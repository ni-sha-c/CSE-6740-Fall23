\documentclass[12pt]{article}
\usepackage[tagged, highstructure]{accessibility}
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[margin=1in]{geometry}
\usepackage{scribe}
\usepackage{listings}
\usepackage{natbib,verbatim}
\usepackage{amsmath,amssymb,amsfonts,mathtools}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=magenta,
    pdftitle={Course Syllabus},
    pdfauthor={Nisha Chandramoorthy},
    pdflang={en-US}
}

%\Scribe{Your Name}
\title{Homework 1_6740}
\LectureNumber{CSE 6740}
\LectureDate{Due Sept 14, '23 (11:59 pm ET) on Gradescope} 
\Lecturer{Cite any sources and collaborators; do not copy. See syllabus for policy.}
\LectureTitle{Homework 1}

\lstset{style=mystyle}

\begin{document}
\MakeScribeTop

In this homework, we will explore some theoretical and algorithmic aspects of Support Vector Machines (SVMs) and Boosting. The  \href{https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html}{breast cancer dataset} from the \href{https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html}{scikit-learn} library will serve as our testbed.

The breast cancer dataset is a classic binary classification dataset from the \href{https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic}{UCI Machine learning repsitory}. The dataset contains 569 samples with labels ``malignant'' or ``benign'' denoting the state of the tumor cells. Each tumor cell is described by a 30-dimensional feature vector that was extracted from digitized images of the cell nuclei. Given a new cell (represented by a 30-dimensional feature vector), the goal is to predict whether the cell is malignant or benign.


\section{Boosting the perceptron}
The breast cancer dataset is not linearly separable. However, a linear classifier learned, e.g., by the perceptron algorithm, is easy to implement and interpret. Here, we will investigate boosting the performance of the perceptron by using it as a \emph{weak learner} in the Adaboost algorithm.


\begin{itemize}
	\item Implement the perceptron algorithm. You may use the \href{https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html}{scikit-learn} implementation to check your work. To do this, first, load the dataset (code below was generated by Github CoPilot) and split it into training and test datasets; the test data consists of 114 samples.
	\begin{lstlisting}[language=Python]
	from sklearn.datasets import load_breast_cancer
	from sklearn.model_selection import train_test_split
	data = load_breast_cancer()
	X = data.data
	y = data.target
	X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
	\end{lstlisting}
	\item[(a)] Since the data are not linearly separable, we do not expect the algorithm to converge. How do you identify a good stopping criterion . (2 pts)

\end{itemize}



\end{document}
